# -*- coding: utf-8 -*-
"""procesamiento_datos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12Hed54rfPWvlGOLcRK4XVVZFO2LVQ3CY
"""

# Importación de las bibliotecas necesarias
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# Cargar los datos desde un archivo CSV
df = pd.read_csv('/content/sample_data/dataEnfermedadRenalNuevo.csv')

# Verificar la estructura del DataFrame
print(df.head())
print(df.info())

print(df.dtypes)

# Lista de columnas a eliminar
columns_to_drop = [
    'FECHA_CORTE', 'DEPARTAMENTO', 'PROVINCIA', 'DISTRITO',
    'RED', 'IPRESS', 'EDAD_MEDICO', 'ID_MEDICO',
    'AREA_HOSPITALARIA', 'SERVICIO_HOSPITALARIO',
    'ACTIVIDAD_HOSPITALARIA', 'FEC_RESULTADO_1', 'FEC_RESULTADO_2'
]

# Eliminar columnas del DataFrame
df = df.drop(columns=columns_to_drop, errors='ignore')

# Confirmar la eliminación
print(f"Columnas después de la eliminación: {df.columns}")

print(df.columns)

if 'ID_PACIENTE' in df.columns and 'FECHA_MUESTRA' in df.columns:
    df['FECHA_MUESTRA'] = pd.to_datetime(df['FECHA_MUESTRA'])  # Convertir FECHA a formato datetime
    df = df.sort_values(by=['ID_PACIENTE', 'FECHA_MUESTRA']).groupby('ID_PACIENTE').tail(1)  # Último registro
else:
    print("Advertencia: No se encontraron las columnas ID_PACIENTE o FECHA_MUESTRA.")

# Asegurar que no haya valores nulos en las columnas de procedimientos y unidades
df['PROCEDIMIENTO_1'] = df['PROCEDIMIENTO_1'].fillna('')
df['PROCEDIMIENTO_2'] = df['PROCEDIMIENTO_2'].fillna('')
df['UNIDADES_1'] = df['UNIDADES_1'].fillna('')
df['UNIDADES_2'] = df['UNIDADES_2'].fillna('')

# Función para convertir valores a mg/dL según la unidad
def convertir_a_mg(resultado, unidad, tipo):
    if unidad.lower() == 'mg/dl':
        return resultado
    elif unidad.lower() == 'mmol/lt':
        if tipo == 'GLUCOSA':
            return resultado * 18  # Conversión para glucosa
        elif tipo == 'CREATININA':
            return resultado * 113.12  # Conversión para creatinina
    else:
        return None  # Unidades no reconocidas

# Crear nuevas columnas para GLUCOSA y CREATININA con conversión de unidades
df['GLUCOSA'] = df.apply(
    lambda row: convertir_a_mg(row['RESULTADO_1'], row['UNIDADES_1'], 'GLUCOSA') if 'GLUCOSA' in str(row['PROCEDIMIENTO_1']).upper() else (
        convertir_a_mg(row['RESULTADO_2'], row['UNIDADES_2'], 'GLUCOSA') if 'GLUCOSA' in str(row['PROCEDIMIENTO_2']).upper() else None
    ), axis=1
)

df['CREATININA'] = df.apply(
    lambda row: convertir_a_mg(row['RESULTADO_1'], row['UNIDADES_1'], 'CREATININA') if 'CREATININA' in str(row['PROCEDIMIENTO_1']).upper() else (
        convertir_a_mg(row['RESULTADO_2'], row['UNIDADES_2'], 'CREATININA') if 'CREATININA' in str(row['PROCEDIMIENTO_2']).upper() else None
    ), axis=1
)

# Verificar el resultado
print(df[['GLUCOSA', 'CREATININA']].head())

# Lista de columnas a eliminar
columns_to_drop = [
    'RESULTADO_1', 'RESULTADO_2', 'PROCEDIMIENTO_1', 'UNIDADES_1','PROCEDIMIENTO_2', 'UNIDADES_2'
]

# Eliminar columnas del DataFrame
df = df.drop(columns=columns_to_drop, errors='ignore')

# Confirmar la eliminación
print(f"Columnas después de la eliminación: {df.columns}")

variables = ['GLUCOSA', 'CREATININA', 'EDAD_PACIENTE']

plt.figure(figsize=(15, 5))
for i, var in enumerate(variables, 1):
    plt.subplot(1, 3, i)
    sns.boxplot(x=df[var])
    plt.title(f'Boxplot de {var}')
plt.tight_layout()
plt.show()

# Graficar histogramas para distribución
plt.figure(figsize=(15, 5))
for i, var in enumerate(variables, 1):
    plt.subplot(1, 3, i)
    sns.histplot(df[var], kde=True, bins=30)
    plt.title(f'Histograma de {var}')
plt.tight_layout()
plt.show()

# Función para eliminar outliers usando el rango intercuartílico (IQR)
def eliminar_outliers(df, columna):
    Q1 = df[columna].quantile(0.25)  # Primer cuartil (25%)
    Q3 = df[columna].quantile(0.75)  # Tercer cuartil (75%)
    IQR = Q3 - Q1  # Rango intercuartílico
    limite_inferior = Q1 - 1.5 * IQR  # Límite inferior
    limite_superior = Q3 + 1.5 * IQR  # Límite superior
    # Filtrar los datos dentro de los límites
    return df[(df[columna] >= limite_inferior) & (df[columna] <= limite_superior)]

# Aplicar la función a las columnas GLUCOSA, CREATININA, y EDAD_PACIENTE
columnas_a_limpiar = ['GLUCOSA', 'CREATININA', 'EDAD_PACIENTE']
for columna in columnas_a_limpiar:
    df = eliminar_outliers(df, columna)

# Verificar la distribución después de eliminar outliers
print(df.describe())

import seaborn as sns
import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

sns.boxplot(df['GLUCOSA'], ax=axes[0]).set_title('Boxplot de GLUCOSA')
sns.boxplot(df['CREATININA'], ax=axes[1]).set_title('Boxplot de CREATININA')
sns.boxplot(df['EDAD_PACIENTE'], ax=axes[2]).set_title('Boxplot de EDAD_PACIENTE')

plt.tight_layout()
plt.show()

df = df.groupby('SEXO_PACIENTE', group_keys=False).apply(
    lambda x: x.sample(frac=0.1, random_state=42)  # Tomar el 10% por grupo
)

# Guardar la muestra limpia
df.to_csv('dataset_muestra_representativa.csv', index=False)

# Graficar la distribución de la muestra
plt.figure(figsize=(10, 5))
sns.countplot(x='SEXO_PACIENTE', data=df)
plt.title('Distribución de SEXO_PACIENTE en la muestra representativa')
plt.show()

print("Estadísticas de la muestra representativa:")
print(df.describe())

# Eliminar las columnas solicitadas
df = df.drop(columns=['UBIGEO', 'ID_PACIENTE', 'FECHA_MUESTRA'])

# Transformar el sexo a valores 1 y 0
df['SEXO_PACIENTE'] = df['SEXO_PACIENTE'].apply(lambda x: 0 if x.upper() == 'FEMENINO' else 1)

# Verificar los resultados
print(df)

data = {
    'COD_DIAG': ['N18.3', 'N18.9', 'N18.6', 'N18.2', 'N18.1', 'N18.4', 'N18.5', 'I12.0', 'I12.9']
}

# Diccionario de clasificación por niveles
cod_diag_niveles = {
    'N18.1': 1,  # Estadio 1
    'N18.2': 2,  # Estadio 2
    'N18.3': 3,  # Estadio 3
    'N18.4': 4,  # Estadio 4
    'N18.5': 5,  # Estadio 5
    'N18.6': 6,  # Falla Renal Terminal
    'N18.9': 0,  # Sin especificar estadio
    'I12.0': 7,  # Hipertensión Nefropática con ERC
    'I12.9': 8  # Hipertensión Nefropática sin ERC
}

# Asignar el nivel de enfermedad a cada código
df['NIVEL_ENFERMEDAD'] = df['COD_DIAG'].map(cod_diag_niveles)

df.describe()

df = df[df['CREATININA'] > 0]

import numpy as np

# Asignar constantes para CKD-EPI
def calcular_tfg(creatinina, edad, sexo):
    if sexo == 1:  # Mujer
        k = 0.7
        alfa = -0.329
        factor_sexo = 1.018
    else:  # Hombre
        k = 0.9
        alfa = -0.411
        factor_sexo = 1.0

    # Fórmula CKD-EPI
    tfg = 141 * min(creatinina / k, 1)**alfa * max(creatinina / k, 1)**(-1.209) * (0.993**edad) * factor_sexo
    return tfg

# Aplicar al dataset
df['TFG'] = df.apply(lambda row: calcular_tfg(row['CREATININA'], row['EDAD_PACIENTE'], row['SEXO_PACIENTE']), axis=1)

# Clasificar el TFG en estadios de ERC
def clasificar_tfg(tfg):
    if tfg >= 90:
        return 1  # Estadio 1
    elif 60 <= tfg < 90:
        return 2  # Estadio 2
    elif 30 <= tfg < 60:
        return 3  # Estadio 3
    elif 15 <= tfg < 30:
        return 4  # Estadio 4
    else:
        return 5  # Estadio 5

# Crear columna de estadio basado en TFG
df['ESTADIO_TFG'] = df['TFG'].apply(clasificar_tfg)

# Mostrar resultado
print(df[['COD_DIAG', 'CREATININA', 'TFG', 'ESTADIO_TFG']])

# Simular columnas adicionales
import numpy as np
np.random.seed(42)
df['ANTECEDENTES'] = np.random.choice([0, 1], size=len(df), p=[0.7, 0.3])  # Antecedentes familiares

df.describe()

df.dtypes

# Eliminar columnas innecesarias del DataFrame actual
columns_to_keep = ['EDAD_PACIENTE', 'SEXO_PACIENTE','GLUCOSA','CREATININA','NIVEL_ENFERMEDAD','TFG','ESTADIO_TFG']
df_filtered = df[columns_to_keep]

# Crear la matriz de correlación desde el DataFrame filtrado
correlation_matrix = df_filtered.corr()

# Graficar el mapa de calor de la matriz de correlación
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap="coolwarm", cbar=True, square=True)
plt.title("Matriz de Correlación del DataFrame Filtrado")
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler

# Seleccionar columnas relevantes
columns_to_keep = [ 'SEXO_PACIENTE','CREATININA', 'EDAD_PACIENTE','NIVEL_ENFERMEDAD', 'ESTADIO_TFG']
df_filtered = df[columns_to_keep]

# Normalizar las columnas (excepto variables categóricas como SEXO_PACIENTE)
#scaler = MinMaxScaler()
#columns_to_normalize = ['EDAD_PACIENTE',  'CREATININA',  'NIVEL_ENFERMEDAD', 'ESTADIO_TFG']
#df_filtered[columns_to_normalize] = scaler.fit_transform(df_filtered[columns_to_normalize])

# Calcular la matriz de correlación
correlation_matrix = df_filtered.corr()

# Graficar el mapa de calor
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap="coolwarm", cbar=True, square=True)
plt.title("Matriz de Correlación del DataFrame Filtrado y Normalizado")
plt.show()

df_filtered.describe()

# Guardar la muestra limpia
df_filtered.to_csv('dataset_muestra_representativa_para_cluster.csv', index=False)

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import RobustScaler

from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# Paso 1: Seleccionar las características para el modelo
X = df_filtered.copy()

# Paso 2: Normalizar los datos
scaler = RobustScaler()
X_scaled = scaler.fit_transform(X)

# Paso 3: Método del codo y coeficiente de silueta
inertia = []
silhouette_scores = []
range_clusters = range(2, 25)

for k in range_clusters:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    inertia.append(kmeans.inertia_)
    labels = kmeans.labels_
    silhouette_avg = silhouette_score(X_scaled, labels)
    silhouette_scores.append(silhouette_avg)

# Graficar el método del codo
plt.figure(figsize=(8, 5))
plt.plot(range_clusters, inertia, marker='o', linestyle='--', label='Inercia')
plt.title('Método del Codo para Selección de Clústeres')
plt.xlabel('Número de Clústeres (k)')
plt.ylabel('Inercia')
plt.legend()
plt.show()

# Graficar el coeficiente de silueta
plt.figure(figsize=(8, 5))
plt.plot(range_clusters, silhouette_scores, marker='o', linestyle='-', label='Silhouette Score', color='orange')
plt.title('Coeficiente de Silueta para Selección de Clústeres')
plt.xlabel('Número de Clústeres (k)')
plt.ylabel('Coeficiente de Silueta')
plt.legend()
plt.show()

# Paso 4: Elegir el número óptimo de clústeres (ajustar según gráficos)
optimal_k = silhouette_scores.index(max(silhouette_scores)) + 2  # +2 porque range_clusters comienza en 2
print(f"Número óptimo de clústeres basado en Silhouette: {optimal_k}")


optimal_k=3


# Reentrenar K-Means con el número óptimo de clústeres
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
#kmeans = KMeans(n_clusters=3, random_state=42)

kmeans.fit(X_scaled)
labels = kmeans.labels_

# Calcular el coeficiente de silueta final
silhouette_avg = silhouette_score(X_scaled, labels)
print(f"Coeficiente de silueta para k={optimal_k}: {silhouette_avg:.2f}")

# Agregar los clústeres al DataFrame
df_filtered['CLUSTER'] = labels

# Analizar distribución de los clústeres
print("Distribución de pacientes en cada clúster:")
print(df_filtered['CLUSTER'].value_counts())

# Visualizar los centroides
centroids = kmeans.cluster_centers_
print("Centroides de los clústeres (estandarizados):")
print(centroids)

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

plt.figure(figsize=(10, 8))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis', s=50, alpha=0.7)
plt.colorbar(label='Cluster')
plt.title('Visualización de Clústeres con K-Means')
plt.xlabel('Componente Principal 1')
plt.ylabel('Componente Principal 2')
plt.show()

cluster_summary = df_filtered.groupby('CLUSTER').mean()
print("Resumen de características por clúster:")
print(cluster_summary)

df_filtered.to_csv('resultados_clustering.csv', index=False)
print("Resultados guardados en 'resultados_clustering.csv'.")

import seaborn as sns
import matplotlib.pyplot as plt

# Visualización: Distribución de edades por clúster
plt.figure(figsize=(10, 6))
sns.boxplot(x='CLUSTER', y='NIVEL_ENFERMEDAD', data=df_filtered)
plt.title('Distribución de ESTADIO_TFG por Clúster')
plt.xlabel('Clúster')
plt.ylabel('Edad')
plt.show()

# Visualización: Promedio de otras variables por clúster
cluster_means = df_filtered.groupby('CLUSTER').mean().reset_index()
cluster_means.plot(kind='bar', x='CLUSTER', figsize=(12, 8))
plt.title('Promedio de Variables Clave por Clúster')
plt.xlabel('Clúster')
plt.ylabel('Promedio')
plt.legend(loc='upper right')
plt.show()

import pickle

# Guardar el escalador en un archivo .pkl
with open('scaler.pkl', 'wb') as scaler_file:
    pickle.dump(scaler, scaler_file)

# Guardar el modelo K-Means en un archivo .pkl
with open('kmeans.pkl', 'wb') as kmeans_file:
    pickle.dump(kmeans, kmeans_file)

print("El escalador y el modelo K-Means han sido guardados exitosamente:")
print("Archivos generados: 'scaler.pkl' y 'kmeans.pkl'")

import pandas as pd
import pickle

# Paso 1: Cargar el scaler y el modelo K-Means
with open('scaler.pkl', 'rb') as scaler_file:
    scaler = pickle.load(scaler_file)

with open('kmeans.pkl', 'rb') as kmeans_file:
    kmeans = pickle.load(kmeans_file)

# Verificar las columnas originales del scaler
print("Columnas originales del scaler:")
print(scaler.feature_names_in_)

# Paso 3: Función para clasificar pacientes
def clasificar_paciente(age, creatinina, glucosa, presion, sod=140, pot=4.5, hemo=13, bu=20):
    """
    Clasifica a un paciente en un clúster basado en sus datos y genera un informe.
    """
    # Calcular TFG
    tfg = calcular_tfg(creatinina, age, es_mujer=False)

    # Escalar los datos del paciente con las características utilizadas en el modelo
    patient_data = pd.DataFrame([[age, presion, glucosa, bu, creatinina, sod, pot, hemo]],
                                 columns=['EDAD_PACIENTE', 'bp', 'bgr', 'bu', 'CREATININA', 'sod', 'pot', 'HEMOGLOBINA'])

    # Ajustar nombres para que coincidan con el modelo entrenado
    patient_data = patient_data.rename(columns={
        'bp': 'PRESION_ARTERIAL',
        'bgr': 'GLUCOSA',
        'bu': 'UREA',
        'sod': 'SODIO',
        'pot': 'POTASIO',
        'CREATININA': 'CREATININA',
        'HEMOGLOBINA': 'HEMOGLOBINA',
        'EDAD_PACIENTE': 'EDAD_PACIENTE'
    })

    # Verificar que todas las columnas esperadas estén presentes
    columnas_faltantes = [col for col in scaler.feature_names_in_ if col not in patient_data.columns]
    for col in columnas_faltantes:
        patient_data[col] = 0  # Valor predeterminado

    # Reordenar las columnas para que coincidan exactamente con las esperadas por el escalador
    patient_data = patient_data[list(scaler.feature_names_in_)]

    # Escalar los datos del paciente
    patient_scaled = scaler.transform(patient_data)

    # Predecir el clúster usando el modelo entrenado
    cluster = kmeans.predict(patient_scaled)[0]

    # Generar un informe clínico
    recomendaciones = {
        0: "Paciente saludable con función renal normal. Se recomienda mantener hábitos saludables.",
        1: "Paciente con función renal moderadamente reducida. Es necesario realizar monitoreo frecuente.",
        2: "Paciente con daño renal severo. Se recomienda atención médica inmediata y tratamiento especializado."
    }

    informe = {
        "TFG (mL/min/1.73m²)": tfg,
        "Clúster asignado": cluster,
        "Estado clínico": recomendaciones.get(cluster, "Estado desconocido. Requiere evaluación adicional."),
        "Datos del paciente": {
            "Edad": age,
            "Creatinina (mg/dL)": creatinina,
            "Glucosa (mg/dL)": glucosa,
            "Presión Arterial (mmHg)": presion,
            "Sodio (mEq/L)": sod,
            "Potasio (mEq/L)": pot,
            "Hemoglobina (g/dL)": hemo,
            "Urea (mg/dL)": bu
        }
    }
    return informe

# Ejemplo: Clasificar un paciente
paciente_ejemplo = clasificar_paciente(age=60, creatinina=6.0, glucosa=200, presion=85)

# Mostrar el informe generado
print(paciente_ejemplo)

import seaborn as sns
import matplotlib.pyplot as plt

# Asegurarte de que la columna CLUSTER es categórica para las visualizaciones
df_filtered['CLUSTER'] = df_filtered['CLUSTER'].astype(str)

# Pairplot para analizar relaciones entre variables clave
sns.pairplot(
    df_filtered,
    vars=['EDAD_PACIENTE', 'CREATININA', 'NIVEL_ENFERMEDAD', 'ESTADIO_TFG'],
    hue='CLUSTER',
    palette='Set2'
)
plt.suptitle('Relación de Variables por Clúster', y=1.02)
plt.show()

# Gráfico de caja (boxplot) para analizar la distribución de creatinina por clúster
plt.figure(figsize=(10, 6))
sns.boxplot(x='CLUSTER', y='CREATININA', data=df_filtered, palette='viridis')
plt.title('Distribución de Creatinina por Clúster')
plt.xlabel('Clúster')
plt.ylabel('Creatinina sérica (mg/dL)')
plt.show()

# Gráfico de caja (boxplot) para analizar la distribución de nivel de enfermedad por clúster
plt.figure(figsize=(10, 6))
sns.boxplot(x='CLUSTER', y='NIVEL_ENFERMEDAD', data=df_filtered, palette='viridis')
plt.title('Distribución de Nivel de Enfermedad por Clúster')
plt.xlabel('Clúster')
plt.ylabel('Nivel de Enfermedad')
plt.show()

# Gráfico de barras para promedio de las variables por clúster
cluster_means = df_filtered.groupby('CLUSTER').mean().reset_index()

# Melt para graficar en forma larga (long-form data)
cluster_means_melted = cluster_means.melt(id_vars=['CLUSTER'], var_name='Variable', value_name='Promedio')

plt.figure(figsize=(12, 8))
sns.barplot(data=cluster_means_melted, x='CLUSTER', y='Promedio', hue='Variable', palette='viridis')
plt.title('Promedio de Variables por Clúster')
plt.xlabel('Clúster')
plt.ylabel('Promedio')
plt.legend(loc='upper right')
plt.show()

